  0%|                                                              | 0/2 [00:00<?, ?it/s]/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/generation/utils.py:2109: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.
  warnings.warn(
Traceback (most recent call last):
  File "/data1/lihaobo/tracking/rft/src/virft/src/open_r1/grpo_tracking.py", line 258, in <module>
    main(script_args, training_args, model_args)
  File "/data1/lihaobo/tracking/rft/src/virft/src/open_r1/grpo_tracking.py", line 248, in main
    trainer.train()
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/trainer.py", line 2243, in train
    return inner_training_loop(
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/trainer.py", line 2550, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/trainer.py", line 3700, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/data1/lihaobo/tracking/rft/src/virft/src/open_r1/trainer/grpo_trainer_tracking.py", line 371, in compute_loss
    prompt_completion_ids = unwrapped_model.generate(**generation_inputs, generation_config=self.generation_config)
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/generation/utils.py", line 2219, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 2097, in _expand_inputs_for_generation
    model_kwargs = _expand_dict_for_generation_visual(model_kwargs)
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 2049, in _expand_dict_for_generation_visual
    samples = torch.split(image_grid_thw, list(image_nums))
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/torch/functional.py", line 207, in split
    return tensor.split(split_size_or_sections, dim)
  File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/torch/_tensor.py", line 983, in split
    return torch._VF.split_with_sizes(self, split_size, dim)
RuntimeError: split_with_sizes expects split_sizes to sum exactly to 3 (input tensor's size at dimension 0), but got split_sizes=[0]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data1/lihaobo/tracking/rft/src/virft/src/open_r1/grpo_tracking.py", line 258, in <module>
[rank0]:     main(script_args, training_args, model_args)
[rank0]:   File "/data1/lihaobo/tracking/rft/src/virft/src/open_r1/grpo_tracking.py", line 248, in main
[rank0]:     trainer.train()
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/trainer.py", line 2243, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/trainer.py", line 2550, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/trainer.py", line 3700, in training_step
[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank0]:   File "/data1/lihaobo/tracking/rft/src/virft/src/open_r1/trainer/grpo_trainer_tracking.py", line 371, in compute_loss
[rank0]:     prompt_completion_ids = unwrapped_model.generate(**generation_inputs, generation_config=self.generation_config)
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/generation/utils.py", line 2219, in generate
[rank0]:     input_ids, model_kwargs = self._expand_inputs_for_generation(
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 2097, in _expand_inputs_for_generation
[rank0]:     model_kwargs = _expand_dict_for_generation_visual(model_kwargs)
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 2049, in _expand_dict_for_generation_visual
[rank0]:     samples = torch.split(image_grid_thw, list(image_nums))
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/torch/functional.py", line 207, in split
[rank0]:     return tensor.split(split_size_or_sections, dim)
[rank0]:   File "/home/lihaobo/miniconda3/envs/track/lib/python3.10/site-packages/torch/_tensor.py", line 983, in split
[rank0]:     return torch._VF.split_with_sizes(self, split_size, dim)
[rank0]: RuntimeError: split_with_sizes expects split_sizes to sum exactly to 3 (input tensor's size at dimension 0), but got split_sizes=[0]
